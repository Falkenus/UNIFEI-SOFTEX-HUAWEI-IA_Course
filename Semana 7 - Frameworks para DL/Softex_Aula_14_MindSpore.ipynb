{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip --default-timeout=1000 install mindspore-gpu"
      ],
      "metadata": {
        "id": "T56SeewqeV2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322bc203-2605-4d10-eac7-50a016e4007e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mindspore-gpu\n",
            "  Downloading mindspore_gpu-1.10.0-cp39-cp39-manylinux1_x86_64.whl (345.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.13.0 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (3.20.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (8.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (1.22.4)\n",
            "Requirement already satisfied: psutil>=5.6.1 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (5.9.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (23.0)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.9/dist-packages (from mindspore-gpu) (1.10.1)\n",
            "Collecting asttokens>=2.0.4\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from asttokens>=2.0.4->mindspore-gpu) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.3->mindspore-gpu) (0.40.0)\n",
            "Installing collected packages: asttokens, mindspore-gpu\n",
            "Successfully installed asttokens-2.2.1 mindspore-gpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mindspore\n",
        "from mindspore import nn, ops\n",
        "from mindspore.dataset import vision, transforms\n",
        "from mindspore.dataset import MnistDataset"
      ],
      "metadata": {
        "id": "pnBGojTElt-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5d62f8-6a33-4756-bcf4-ff7706730ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WARNING] ME(448:139721996076864,MainProcess):2023-04-12-23:40:16.954.250 [mindspore/run_check/_check_version.py:79] MindSpore version 1.10.0 and cuda version 11.8.89 does not match, CUDA version [['10.1', '11.1', '11.6']] are supported by MindSpore officially. Please refer to the installation guide for version matching information: https://www.mindspore.cn/install.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing a Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "T2B5_yDVgfpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MindSpore provides Pipeline-based [Data Engine](https://www.mindspore.cn/docs/zh-CN/master/design/data_engine.html) and achieves efficient data preprocessing through [Dataset](https://www.mindspore.cn/tutorials/en/master/beginner/dataset.html) and [Transforms](https://www.mindspore.cn/tutorials/en/master/beginner/transforms.html). In this tutorial, we use the Mnist dataset and pre-process dataset by using the data transformations provided by `mindspore.dataset`, after automatically downloaded.\n"
      ],
      "metadata": {
        "id": "TnV4ab1ggiRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip\n",
        "!unzip MNIST_Data.zip"
      ],
      "metadata": {
        "id": "kCWOyH6IgJPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6248b2f-4b61-4a92-b104-6138385733d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-12 23:40:19--  https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip\n",
            "Resolving mindspore-website.obs.cn-north-4.myhuaweicloud.com (mindspore-website.obs.cn-north-4.myhuaweicloud.com)... 49.4.112.92, 49.4.112.91, 121.36.121.84\n",
            "Connecting to mindspore-website.obs.cn-north-4.myhuaweicloud.com (mindspore-website.obs.cn-north-4.myhuaweicloud.com)|49.4.112.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10754903 (10M) [application/zip]\n",
            "Saving to: ‘MNIST_Data.zip’\n",
            "\n",
            "MNIST_Data.zip      100%[===================>]  10.26M  6.37MB/s    in 1.6s    \n",
            "\n",
            "2023-04-12 23:40:22 (6.37 MB/s) - ‘MNIST_Data.zip’ saved [10754903/10754903]\n",
            "\n",
            "Archive:  MNIST_Data.zip\n",
            "   creating: MNIST_Data/test/\n",
            "  inflating: MNIST_Data/test/t10k-images-idx3-ubyte  \n",
            "  inflating: MNIST_Data/test/t10k-labels-idx1-ubyte  \n",
            "   creating: MNIST_Data/train/\n",
            "  inflating: MNIST_Data/train/train-images-idx3-ubyte  \n",
            "  inflating: MNIST_Data/train/train-labels-idx1-ubyte  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MnistDataset('MNIST_Data/train')\n",
        "test_dataset = MnistDataset('MNIST_Data/test')\n",
        "\n",
        "print(train_dataset.get_col_names())"
      ],
      "metadata": {
        "id": "E_SlkNWdf-zX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1f24d6-8943-4eb5-f288-d1fe2fd6490f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "5JhxBJ3Wo_eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262d19a0-221a-464d-bbc1-8973efa571a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mindspore.dataset.engine.datasets_vision.MnistDataset at 0x7f129d9a8b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.create_tuple_iterator()"
      ],
      "metadata": {
        "id": "MvqhC_xPo699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0abe832-0b2e-4fc2-aa40-6f282af933ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mindspore.dataset.engine.iterators.TupleIterator at 0x7f129d961310>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset in MindSpore uses the Data Processing Pipeline, which requires specifying operations such as map, batch, and shuffle. Here we use `map` to transform the image data and the label, and then pack the processed dataset into a batch of size 64."
      ],
      "metadata": {
        "id": "n6oWZE1agnW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datapipe(dataset, batch_size):\n",
        "  image_transforms = [\n",
        "    vision.Rescale(1.0 / 255.0, 0),\n",
        "    vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
        "    vision.HWC2CHW(),\n",
        "  ]\n",
        "\n",
        "  label_transform = transforms.TypeCast(mindspore.int32)\n",
        "\n",
        "  dataset = dataset.map(image_transforms, 'image')\n",
        "  dataset = dataset.map(label_transform, 'label')\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset\n",
        "\n",
        "train_dataset = datapipe(train_dataset, 64)\n",
        "test_dataset = datapipe(train_dataset, 64)"
      ],
      "metadata": {
        "id": "615X1pfvgoua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.get_col_names()"
      ],
      "metadata": {
        "id": "56rYVuxCoHCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77567fa4-3486-4c1a-fa0c-23ecb92d1acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['image', 'label']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in test_dataset.create_tuple_iterator():\n",
        "    print(f\"Shape of image [N, C, H, W]: {image.shape} {image.dtype}\")\n",
        "    print(f\"Shape of label: {label.shape} {label.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "b3I_BVN7lON2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "ce917163-8f0d-446a-d0a6-1158e063d7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c85939261556>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tuple_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of image [N, C, H, W]: {image.shape} {image.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of label: {label.shape} {label.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Note offload is applied inside _get_next() if applicable since get_next converts to output format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m_get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffload_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error. map operation: [HWC2CHW] failed. HWC2CHW: image shape should be <H,W> or <H,W,C>, but got rank: 4\nLine of code : 683\nFile         : mindspore/ccsrc/minddata/dataset/kernels/image/image_utils.cc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Network"
      ],
      "metadata": {
        "id": "tx0mMHUFiABa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`mindspore.nn` class is the base class for building all networks and is the basic unit of the network. When the user needs to customize the network, you can inherit the `nn.Cell` class and override the `__init__` method and the `construct` method. `__init__` contains the definitions of all network layers, and `construct` contains the transformation process of the data ([Tensor](https://www.mindspore.cn/tutorials/en/master/beginner/tensor.html)) (i.e. the construction process of the [computational graph](https://www.mindspore.cn/tutorials/en/master/advanced/compute_graph.html))."
      ],
      "metadata": {
        "id": "Vqzkk-LyiCRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class Network(nn.Cell):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dense_relu_sequential = nn.SequentialCell(\n",
        "      nn.Dense(28*28, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dense(512, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dense(512, 10)\n",
        "    )\n",
        "\n",
        "  def construct(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.dense_relu_sequential(x)\n",
        "    return logits\n",
        "\n",
        "model = Network()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "oH4YxzwIiVRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "2_QyDFr4ieyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = nn.SGD(model.trainable_params(), 1e-2)"
      ],
      "metadata": {
        "id": "Z1k8DQU7ihKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In model training, a complete training process (step) requires the following three steps:\n",
        "\n",
        "1. **Forward calculation**: model predicts results (logits) and finds the prediction loss (loss) with the correct label (label).\n",
        "2. **Backpropagation**: Using an automatic differentiation mechanism, the gradients of the model parameters (parameters) with respect to the loss are automatically found.\n",
        "3. **Parameter optimization**: update the gradient to the parameter.\n",
        "\n",
        "MindSpore uses a functional automatic differentiation mechanism, implemented through the steps above:\n",
        "\n",
        "1. Define forward calculation function.\n",
        "2. Obtain the gradient calculation function by function transformation.\n",
        "3. Define training functions, and perform forward computation, back propagation and parameter optimization."
      ],
      "metadata": {
        "id": "dh-jJsETi73q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define forward function\n",
        "def forward_fn(data, label):\n",
        "  logits = model(data)\n",
        "  loss = loss_fn(logits, label)\n",
        "  return loss, logits\n",
        "\n",
        "# Get gradient function\n",
        "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
        "#grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
        "\n",
        "# Define function of one-step training\n",
        "def train_step(data, label):\n",
        "  (loss, _), grads = grad_fn(data, label)\n",
        "  optimizer(grads)\n",
        "  return loss\n",
        "\n",
        "def train(model, dataset):\n",
        "  size = dataset.get_dataset_size()\n",
        "  model.set_train()\n",
        "  for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
        "    loss = train_step(data, label)\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.asnumpy(), batch\n",
        "      print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")"
      ],
      "metadata": {
        "id": "EWnGA_GOi-zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to training, we define test functions that are used to evaluate the performance of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "hUXg6uDUkxdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataset, loss_fn):\n",
        "  num_batches = dataset.get_dataset_size()\n",
        "  model.set_train(False)\n",
        "  total, test_loss, correct = 0, 0, 0\n",
        "  for data, label in dataset.create_tuple_iterator():\n",
        "    pred = model(data)\n",
        "    total += len(data)\n",
        "    test_loss += loss_fn(pred, label).asnumpy()\n",
        "    correct += (pred.argmax(1) == label).asnumpy().sum()\n",
        "  test_loss /= num_batches\n",
        "  correct /= total\n",
        "  print(f\"Test: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "YQ-MB8MskzVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process requires several iterations of the dataset, and one complete iteration is called an epoch. In each round, the training set is traversed for training and the test set is used for prediction at the end. The loss value and prediction accuracy (Accuracy) of each round are printed, and it can be seen that the loss is decreasing and Accuracy is increasing."
      ],
      "metadata": {
        "id": "g-rSmlq7k6GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(model, train_dataset)\n",
        "    test(model, test_dataset, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "bMCdZT9Qk9tY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}